{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42fec490-63e6-4efe-b22d-93a8fee1d688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‚ Fold 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f06d80d2bac41b9871aa63046215d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/32.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ast\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ast\\.cache\\huggingface\\hub\\models--timm--densenet121.ra_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.1305\n",
      "Epoch 2/10, Loss: 0.7377\n",
      "Epoch 3/10, Loss: 0.4828\n",
      "Epoch 4/10, Loss: 0.3555\n",
      "Epoch 5/10, Loss: 0.2833\n",
      "Epoch 6/10, Loss: 0.1997\n",
      "Epoch 7/10, Loss: 0.1748\n",
      "Epoch 8/10, Loss: 0.1184\n",
      "Epoch 9/10, Loss: 0.0979\n",
      "Epoch 10/10, Loss: 0.0882\n",
      "âœ… Fold 1 - Accuracy: 42.86%, F1 Score: 0.4232\n",
      "\n",
      "ðŸ“‚ Fold 2\n",
      "Epoch 1/10, Loss: 1.1720\n",
      "Epoch 2/10, Loss: 0.7534\n",
      "Epoch 3/10, Loss: 0.5874\n",
      "Epoch 4/10, Loss: 0.5175\n",
      "Epoch 5/10, Loss: 0.4536\n",
      "Epoch 6/10, Loss: 0.3973\n",
      "Epoch 7/10, Loss: 0.3550\n",
      "Epoch 8/10, Loss: 0.3166\n",
      "Epoch 9/10, Loss: 0.3023\n",
      "Epoch 10/10, Loss: 0.2880\n",
      "âœ… Fold 2 - Accuracy: 45.00%, F1 Score: 0.4157\n",
      "\n",
      "ðŸ“‚ Fold 3\n",
      "Epoch 1/10, Loss: 1.1920\n",
      "Epoch 2/10, Loss: 0.7585\n",
      "Epoch 3/10, Loss: 0.6255\n",
      "Epoch 4/10, Loss: 0.4773\n",
      "Epoch 5/10, Loss: 0.4088\n",
      "Epoch 6/10, Loss: 0.3977\n",
      "Epoch 7/10, Loss: 0.3404\n",
      "Epoch 8/10, Loss: 0.3356\n",
      "Epoch 9/10, Loss: 0.2956\n",
      "Epoch 10/10, Loss: 0.2744\n",
      "âœ… Fold 3 - Accuracy: 50.00%, F1 Score: 0.5219\n",
      "\n",
      "ðŸ“‚ Fold 4\n",
      "Epoch 1/10, Loss: 1.1169\n",
      "Epoch 2/10, Loss: 0.7490\n",
      "Epoch 3/10, Loss: 0.5659\n",
      "Epoch 4/10, Loss: 0.4832\n",
      "Epoch 5/10, Loss: 0.3982\n",
      "Epoch 6/10, Loss: 0.4082\n",
      "Epoch 7/10, Loss: 0.3459\n",
      "Epoch 8/10, Loss: 0.3024\n",
      "Epoch 9/10, Loss: 0.3082\n",
      "Epoch 10/10, Loss: 0.3095\n",
      "âœ… Fold 4 - Accuracy: 40.00%, F1 Score: 0.3587\n",
      "\n",
      "ðŸ“‚ Fold 5\n",
      "Epoch 1/10, Loss: 1.1607\n",
      "Epoch 2/10, Loss: 0.7925\n",
      "Epoch 3/10, Loss: 0.5743\n",
      "Epoch 4/10, Loss: 0.4998\n",
      "Epoch 5/10, Loss: 0.4073\n",
      "Epoch 6/10, Loss: 0.3965\n",
      "Epoch 7/10, Loss: 0.2984\n",
      "Epoch 8/10, Loss: 0.3707\n",
      "Epoch 9/10, Loss: 0.3220\n",
      "Epoch 10/10, Loss: 0.2539\n",
      "âœ… Fold 5 - Accuracy: 65.00%, F1 Score: 0.6558\n",
      "\n",
      "ðŸ“Š Average Results over 5 folds:\n",
      "Fold 1: Accuracy = 42.86%, F1 Score = 0.4232\n",
      "Fold 2: Accuracy = 45.00%, F1 Score = 0.4157\n",
      "Fold 3: Accuracy = 50.00%, F1 Score = 0.5219\n",
      "Fold 4: Accuracy = 40.00%, F1 Score = 0.3587\n",
      "Fold 5: Accuracy = 65.00%, F1 Score = 0.6558\n",
      "\n",
      "Overall Average: Accuracy = 48.57%, F1 Score = 0.4751\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import timm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# âœ… DenseNet-121 ë¶„ë¥˜ ëª¨ë¸ ì •ì˜\n",
    "class DenseNetClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNetClassifier, self).__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            'densenet121', pretrained=True, num_classes=3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# âœ… ì‚¬ìš©ìž ì •ì˜ ë°ì´í„°ì…‹\n",
    "class ScrapClassificationDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, label_encoder=None):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.label_encoder = label_encoder or LabelEncoder()\n",
    "        self.data['class_idx'] = self.label_encoder.fit_transform(self.data['weight_class'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.data.iloc[idx]['filename'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = torch.tensor(self.data.iloc[idx]['class_idx'], dtype=torch.long)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# âœ… í‰ê°€ í•¨ìˆ˜\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds) * 100\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    return acc, f1\n",
    "\n",
    "# âœ… ê²½ë¡œ ì„¤ì •\n",
    "csv_path = r\"C:\\Users\\ast\\Documents\\project\\weight.xlsx\"\n",
    "img_dir = r\"C:\\Users\\ast\\Documents\\project\\dataset\"\n",
    "\n",
    "# âœ… ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "df = pd.read_excel(csv_path)\n",
    "df['weight_class'] = pd.qcut(df['KG'], q=3, labels=['light', 'medium', 'heavy'])\n",
    "df['filename'] = df['No'].apply(lambda x: f\"{int(x):03d}.JPG\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# âœ… K-Fold í•™ìŠµ\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "    print(f\"\\nðŸ“‚ Fold {fold+1}\")\n",
    "\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    train_dataset = ScrapClassificationDataset(train_df, img_dir, transform, label_encoder)\n",
    "    val_dataset = ScrapClassificationDataset(val_df, img_dir, transform, label_encoder)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    model = DenseNetClassifier().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    acc, f1 = evaluate_model(model, val_loader, device)\n",
    "    print(f\"âœ… Fold {fold+1} - Accuracy: {acc:.2f}%, F1 Score: {f1:.4f}\")\n",
    "    fold_results.append((acc, f1))\n",
    "\n",
    "# âœ… ì „ì²´ í‰ê·  ì¶œë ¥\n",
    "avg_acc, avg_f1 = np.mean(fold_results, axis=0)\n",
    "print(\"\\nðŸ“Š Average Results over 5 folds:\")\n",
    "for i, (acc, f1) in enumerate(fold_results):\n",
    "    print(f\"Fold {i+1}: Accuracy = {acc:.2f}%, F1 Score = {f1:.4f}\")\n",
    "print(f\"\\nOverall Average: Accuracy = {avg_acc:.2f}%, F1 Score = {avg_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2862251-577a-4820-a629-73e8f4b06698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
