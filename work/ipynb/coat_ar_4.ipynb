{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf54f53-9681-450c-b2f3-ec24b852ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "대조군) 기본 학습값\n",
    "실험군1) 기존 상하좌우 반전 (p=1이면 안됨) + 명도/대비 조정\n",
    "실험군2) 데이터 증강 안 하고 그냥 9배로 복사만 한 경우\n",
    "실험군3) 노이즈까지 추가한 경우 (coat_ar_noise.ipyb참조)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0398aec1-3b03-46c7-993f-6828ce08521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] Loss=1.1468\n",
      "[2/5] Loss=0.6229\n",
      "[3/5] Loss=0.2321\n",
      "[4/5] Loss=0.0502\n",
      "[5/5] Loss=0.0159\n",
      "✅ Control-Base  Acc=0.4286  Macro-F1=0.4339\n",
      "📄 Metrics → result_control_base.json\n",
      "📄 Preds   → pred_control_base.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "run_control_base.py — 대조군 (증강 없음, 기본 학습값)\n",
    "출력 : result_control_base.json  /  pred_control_base.csv\n",
    "\"\"\"\n",
    "\n",
    "# ───────── 0. import\n",
    "import os, json, random, warnings\n",
    "import numpy as np, pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ───────── 1. 하이퍼파라미터 / 경로 \n",
    "SEED = 42\n",
    "CSV_PATH = r\"C:\\Users\\ast\\Documents\\project\\train.csv\"\n",
    "IMG_DIR  = r\"C:\\Users\\ast\\Documents\\project\\train_images\"\n",
    "BATCH = 8\n",
    "EPOCHS = 5\n",
    "LR = 1e-4\n",
    "WD = 0.01                     \n",
    "SMOOTH = 0.0\n",
    "\n",
    "OUT_MET = \"result_control_base.json\"\n",
    "OUT_PRED = \"pred_control_base.csv\"\n",
    "SPLIT_JSON = \"split42.json\"\n",
    "\n",
    "# ───────── 2. 시드 & 멀티프로세싱\n",
    "def seed_everything(s):\n",
    "    random.seed(s); np.random.seed(s); os.environ[\"PYTHONHASHSEED\"]=str(s)\n",
    "    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
    "    torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "seed_everything(SEED)\n",
    "import torch.multiprocessing as mp\n",
    "if mp.get_start_method(allow_none=True) != \"spawn\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "# ───────── 3. Dataset\n",
    "class ScrapDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, tf, label_enc):\n",
    "        self.df  = df.reset_index(drop=True).copy()\n",
    "        self.dir = img_dir\n",
    "        self.tf  = tf\n",
    "        self.df[\"cls\"] = label_enc.transform(self.df[\"weight_class\"])\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(os.path.join(self.dir, row.filename)).convert(\"RGB\")\n",
    "        img = self.tf(img)\n",
    "        return img, torch.tensor(row.cls), row.filename\n",
    "\n",
    "plain_tf = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# ───────── 4. split 고정\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "if os.path.exists(SPLIT_JSON):\n",
    "    idx = json.load(open(SPLIT_JSON)); train_idx, test_idx = idx[\"train\"], idx[\"test\"]\n",
    "else:\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        range(len(df)), test_size=0.2,\n",
    "        stratify=df[\"weight_class\"], random_state=SEED)\n",
    "    json.dump({\"train\":train_idx, \"test\":test_idx}, open(SPLIT_JSON,\"w\"))\n",
    "train_df, test_df = df.iloc[train_idx], df.iloc[test_idx]\n",
    "le = LabelEncoder().fit(train_df[\"weight_class\"])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    ScrapDataset(train_df, IMG_DIR, plain_tf, le),\n",
    "    batch_size=BATCH, shuffle=True, num_workers=0)\n",
    "test_loader  = DataLoader(\n",
    "    ScrapDataset(test_df,  IMG_DIR, plain_tf, le),\n",
    "    batch_size=BATCH, shuffle=False, num_workers=0)\n",
    "\n",
    "# ───────── 5. 모델\n",
    "class CoaTMedium(nn.Module):\n",
    "    def __init__(self, n_cls):\n",
    "        super().__init__()\n",
    "        self.net = timm.create_model('coat_lite_medium',\n",
    "                                     pretrained=True, num_classes=n_cls)\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = CoaTMedium(len(le.classes_)).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "criterion  = nn.CrossEntropyLoss(label_smoothing=SMOOTH)\n",
    "\n",
    "# ───────── 6. 학습\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train(); total=0\n",
    "    for xb, yb, _ in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad(); loss = criterion(model(xb), yb)\n",
    "        loss.backward(); optimizer.step()\n",
    "        total += loss.item()*xb.size(0)\n",
    "    print(f\"[{ep}/{EPOCHS}] Loss={total/len(train_loader.dataset):.4f}\")\n",
    "\n",
    "# ───────── 7. 평가\n",
    "model.eval(); yt, yp, rows = [], [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb, f in test_loader:\n",
    "        pred = model(xb.to(device)).argmax(1).cpu()\n",
    "        yt += yb.tolist(); yp += pred.tolist()\n",
    "        rows += list(zip(f, le.inverse_transform(pred.numpy())))\n",
    "acc = accuracy_score(yt, yp)\n",
    "f1  = f1_score(yt, yp, average=\"macro\")\n",
    "print(f\"✅ Control-Base  Acc={acc:.4f}  Macro-F1={f1:.4f}\")\n",
    "\n",
    "# ───────── 8. 저장\n",
    "json.dump({\"experiment\":\"control_base\",\"accuracy\":acc,\"macro_f1\":f1},\n",
    "          open(OUT_MET,\"w\"), indent=2)\n",
    "pd.DataFrame(rows, columns=[\"filename\",\"predicted_label\"]).to_csv(OUT_PRED, index=False)\n",
    "print(f\"📄 Metrics → {OUT_MET}\\n📄 Preds   → {OUT_PRED}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bd75e95-bccd-473c-93af-ae0ea14817a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] Loss=1.1140\n",
      "[2/10] Loss=0.6211\n",
      "[3/10] Loss=0.3182\n",
      "[4/10] Loss=0.2022\n",
      "[5/10] Loss=0.1760\n",
      "[6/10] Loss=0.1735\n",
      "[7/10] Loss=0.1729\n",
      "[8/10] Loss=0.1723\n",
      "[9/10] Loss=0.1719\n",
      "[10/10] Loss=0.1717\n",
      "✅ Control-EP10-BS16  Acc=0.5238  Macro-F1=0.5235\n",
      "📄 Metrics → result_control_ep10_bs16.json\n",
      "📄 Preds   → pred_control_ep10_bs16.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "run_control_base.py — 대조군 (증강 없음, 기본 학습값)\n",
    "출력 : result_control_base.json  /  pred_control_base.csv\n",
    "\"\"\"\n",
    "\n",
    "# ─── 0. 기본 import\n",
    "import os, json, random, math, warnings, numpy as np, pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ─── 1. 하이퍼파라미터 / 경로\n",
    "SEED = 42\n",
    "CSV  = r\"C:\\Users\\ast\\Documents\\project\\train.csv\"\n",
    "IMG  = r\"C:\\Users\\ast\\Documents\\project\\train_images\"\n",
    "BATCH  = 16         \n",
    "EPOCHS = 10         \n",
    "LR     = 1e-4\n",
    "WD     = 3e-4       \n",
    "SMOOTH = 0.05        \n",
    "\n",
    "SPLIT  = \"split42.json\"\n",
    "OUT_MET = \"result_control_ep10_bs16.json\"\n",
    "OUT_PRE = \"pred_control_ep10_bs16.csv\"\n",
    "\n",
    "# ─── 2. 시드 & 멀티프로세싱\n",
    "def seed_all(s):\n",
    "    random.seed(s); np.random.seed(s); os.environ[\"PYTHONHASHSEED\"]=str(s)\n",
    "    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
    "    torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "seed_all(SEED)\n",
    "import torch.multiprocessing as mp\n",
    "if mp.get_start_method(allow_none=True) != \"spawn\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "# ─── 3. Dataset\n",
    "class ScrapDS(Dataset):\n",
    "    def __init__(self, df, tf, le):\n",
    "        self.df=df.reset_index(drop=True).copy()\n",
    "        self.dir=IMG; self.tf=tf\n",
    "        self.df[\"cls\"]=le.transform(self.df[\"weight_class\"])\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self,i):\n",
    "        row=self.df.iloc[i]\n",
    "        img=Image.open(os.path.join(self.dir,row.filename)).convert(\"RGB\")\n",
    "        return self.tf(img), torch.tensor(row.cls), row.filename\n",
    "\n",
    "plain_tf=transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3,[0.5]*3)\n",
    "])\n",
    "\n",
    "# ─── 4. split 고정\n",
    "df=pd.read_csv(CSV)\n",
    "if os.path.exists(SPLIT):\n",
    "    idx=json.load(open(SPLIT)); train_idx, test_idx=idx[\"train\"], idx[\"test\"]\n",
    "else:\n",
    "    train_idx, test_idx=train_test_split(range(len(df)), test_size=0.2,\n",
    "        stratify=df[\"weight_class\"], random_state=SEED)\n",
    "    json.dump({\"train\":train_idx,\"test\":test_idx}, open(SPLIT,\"w\"))\n",
    "\n",
    "tr_df, te_df = df.iloc[train_idx], df.iloc[test_idx]\n",
    "le = LabelEncoder().fit(tr_df[\"weight_class\"])\n",
    "\n",
    "train_ld = DataLoader(ScrapDS(tr_df, plain_tf, le), batch_size=BATCH,\n",
    "                      shuffle=True , num_workers=0)\n",
    "test_ld  = DataLoader(ScrapDS(te_df, plain_tf, le), batch_size=BATCH,\n",
    "                      shuffle=False, num_workers=0)\n",
    "\n",
    "# ─── 5. 모델 & Optim & Scheduler\n",
    "class CoaTMedium(nn.Module):\n",
    "    def __init__(self, n_cls):\n",
    "        super().__init__()\n",
    "        # timm backbone\n",
    "        self.net = timm.create_model(\n",
    "            'coat_lite_medium',\n",
    "            pretrained=True,\n",
    "            num_classes=n_cls\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=CoaTMedium(len(le.classes_)).to(device)\n",
    "optimizer=torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "total_steps=len(train_ld)*EPOCHS\n",
    "warmup_steps=len(train_ld)       # 1 epoch warm-up\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_steps:\n",
    "        return (step+1)/warmup_steps\n",
    "    prog=(step-warmup_steps)/(total_steps-warmup_steps)\n",
    "    return 0.5*(1+math.cos(math.pi*prog))\n",
    "scheduler=torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=SMOOTH)\n",
    "\n",
    "# ─── 6. 학습\n",
    "for ep in range(1,EPOCHS+1):\n",
    "    model.train(); loss_sum=0\n",
    "    for xb,yb,_ in train_ld:\n",
    "        xb,yb=xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad(); loss=criterion(model(xb), yb)\n",
    "        loss.backward(); optimizer.step(); scheduler.step()\n",
    "        loss_sum += loss.item()*xb.size(0)\n",
    "    print(f\"[{ep}/{EPOCHS}] Loss={loss_sum/len(train_ld.dataset):.4f}\")\n",
    "\n",
    "# ─── 7. 평가\n",
    "model.eval(); yt,yp,rows=[],[],[]\n",
    "with torch.no_grad():\n",
    "    for xb,yb,f in test_ld:\n",
    "        p=model(xb.to(device)).argmax(1).cpu()\n",
    "        yt+=yb.tolist(); yp+=p.tolist()\n",
    "        rows+=list(zip(f, le.inverse_transform(p.numpy())))\n",
    "acc=accuracy_score(yt,yp)\n",
    "f1 = f1_score(yt,yp,average=\"macro\")\n",
    "print(f\"✅ Control-EP10-BS16  Acc={acc:.4f}  Macro-F1={f1:.4f}\")\n",
    "\n",
    "# ─── 8. 저장\n",
    "json.dump({\"experiment\":\"control_ep10_bs16\",\"accuracy\":acc,\"macro_f1\":f1},\n",
    "          open(OUT_MET,\"w\"), indent=2)\n",
    "pd.DataFrame(rows, columns=[\"filename\",\"predicted_label\"])\\\n",
    "  .to_csv(OUT_PRE, index=False)\n",
    "print(f\"📄 Metrics → {OUT_MET}\\n📄 Preds   → {OUT_PRE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aca1c0b-58dc-4221-949a-5dd17fb1f83b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] Loss=0.5999\n",
      "[2/10] Loss=0.1821\n",
      "[3/10] Loss=0.1726\n",
      "[4/10] Loss=0.1703\n",
      "[5/10] Loss=0.1698\n",
      "[6/10] Loss=0.1696\n",
      "[7/10] Loss=0.1695\n",
      "[8/10] Loss=0.1695\n",
      "[9/10] Loss=0.1695\n",
      "[10/10] Loss=0.1694\n",
      "✅ Exp1-FlipColor-9x  Acc=0.4667  Macro-F1=0.4685\n",
      "📄 Metrics → result_exp1_flip_color_9x.json\n",
      "📄 Preds   → pred_exp1_flip_color_9x.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "run_exp1_flip_color_9x.py — 실험군 1\n",
    "  • Train : 70개 원본 × 9배 = 630 이미지\n",
    "            (Random H/V Flip 0.5 + ColorJitter 0.2/0.2)\n",
    "  • Test  : 남은 30개 원본 그대로\n",
    "  • split42_70-30.json 재사용, seed 42 고정\n",
    "출력 : result_exp1_flip_color_9x.json / pred_exp1_flip_color_9x.csv\n",
    "\"\"\"\n",
    "\n",
    "# ───────── 0. import & 공통 설정\n",
    "import os, json, random, math, warnings, numpy as np, pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ───────── 1. 하이퍼파라미터 (대조군과 동일)\n",
    "SEED   = 42\n",
    "CSV    = r\"C:\\Users\\ast\\Documents\\project\\train.csv\"\n",
    "IMG    = r\"C:\\Users\\ast\\Documents\\project\\train_images\"\n",
    "BATCH  = 16\n",
    "EPOCHS = 10\n",
    "LR     = 1e-4\n",
    "WD     = 3e-4\n",
    "SMOOTH = 0.05\n",
    "SPLIT  = \"split42_70-30.json\"           \n",
    "OUT_MET= \"result_exp1_flip_color_9x.json\"\n",
    "OUT_PRE= \"pred_exp1_flip_color_9x.csv\"\n",
    "\n",
    "# 시드 고정\n",
    "def seed_all(s):\n",
    "    random.seed(s); np.random.seed(s); os.environ[\"PYTHONHASHSEED\"]=str(s)\n",
    "    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
    "    torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "seed_all(SEED)\n",
    "import torch.multiprocessing as mp\n",
    "if mp.get_start_method(allow_none=True) != \"spawn\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "# ───────── 2. Dataset 정의\n",
    "class ScrapDS(Dataset):\n",
    "    def __init__(self, df, tf, le):\n",
    "        self.df=df.reset_index(drop=True).copy()\n",
    "        self.dir=IMG; self.tf=tf\n",
    "        self.df[\"cls\"]=le.transform(self.df[\"weight_class\"])\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        row=self.df.iloc[i]\n",
    "        img=Image.open(os.path.join(self.dir, row.filename)).convert(\"RGB\")\n",
    "        return self.tf(img), torch.tensor(row.cls), row.filename\n",
    "\n",
    "# ───────── 3. Transform\n",
    "aug_tf = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "plain_tf = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# ───────── 4. split 70 / 30 고정\n",
    "df = pd.read_csv(CSV)\n",
    "if os.path.exists(SPLIT):\n",
    "    idx=json.load(open(SPLIT)); train_idx, test_idx=idx[\"train\"], idx[\"test\"]\n",
    "else:\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        range(len(df)), train_size=70, test_size=30,\n",
    "        stratify=df[\"weight_class\"], random_state=SEED)\n",
    "    json.dump({\"train\":train_idx, \"test\":test_idx}, open(SPLIT,\"w\"))\n",
    "\n",
    "tr_df, te_df = df.iloc[train_idx], df.iloc[test_idx]\n",
    "le = LabelEncoder().fit(tr_df[\"weight_class\"])\n",
    "\n",
    "# ───────── 5. Train / Test DataLoader\n",
    "base_train_ds = ScrapDS(tr_df, aug_tf, le)\n",
    "train_ds      = ConcatDataset([base_train_ds]*9)   # 70 × 9 = 630\n",
    "test_ds       = ScrapDS(te_df, plain_tf, le)\n",
    "\n",
    "train_ld = DataLoader(train_ds, batch_size=BATCH, shuffle=True , num_workers=0)\n",
    "test_ld  = DataLoader(test_ds , batch_size=BATCH, shuffle=False, num_workers=0)\n",
    "\n",
    "# ───────── 6. 모델, Optim, Scheduler\n",
    "class CoaTMedium(nn.Module):\n",
    "    def __init__(self, n_cls):\n",
    "        super().__init__()\n",
    "        # timm backbone ─ 들여쓰기 8칸(=4스페이스×2)\n",
    "        self.net = timm.create_model(\n",
    "            'coat_lite_medium',\n",
    "            pretrained=True,\n",
    "            num_classes=n_cls\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CoaTMedium(len(le.classes_)).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "total_steps=len(train_ld)*EPOCHS\n",
    "warmup_steps=len(train_ld)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lambda step: (step+1)/warmup_steps if step<warmup_steps\n",
    "                 else 0.5*(1+math.cos(math.pi*(step-warmup_steps)/(total_steps-warmup_steps)))\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=SMOOTH)\n",
    "\n",
    "# ───────── 7. 학습\n",
    "for ep in range(1,EPOCHS+1):\n",
    "    model.train(); loss_sum=0\n",
    "    for xb,yb,_ in train_ld:\n",
    "        xb,yb=xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad(); loss=criterion(model(xb), yb)\n",
    "        loss.backward(); optimizer.step(); scheduler.step()\n",
    "        loss_sum += loss.item()*xb.size(0)\n",
    "    print(f\"[{ep}/{EPOCHS}] Loss={loss_sum/len(train_ld.dataset):.4f}\")\n",
    "\n",
    "# ───────── 8. 평가\n",
    "model.eval(); yt,yp,rows=[],[],[]\n",
    "with torch.no_grad():\n",
    "    for xb,yb,f in test_ld:\n",
    "        p=model(xb.to(device)).argmax(1).cpu()\n",
    "        yt+= yb.tolist(); yp+= p.tolist()\n",
    "        rows+=list(zip(f, le.inverse_transform(p.numpy())))\n",
    "acc = accuracy_score(yt,yp)\n",
    "f1  = f1_score(yt,yp,average=\"macro\")\n",
    "print(f\"✅ Exp1-FlipColor-9x  Acc={acc:.4f}  Macro-F1={f1:.4f}\")\n",
    "\n",
    "# ───────── 9. 저장\n",
    "json.dump({\"experiment\":\"exp1_flip_color_9x\",\"accuracy\":acc,\"macro_f1\":f1},\n",
    "          open(OUT_MET,\"w\"), indent=2)\n",
    "pd.DataFrame(rows, columns=[\"filename\",\"predicted_label\"])\\\n",
    "  .to_csv(OUT_PRE, index=False)\n",
    "print(f\"📄 Metrics → {OUT_MET}\\n📄 Preds   → {OUT_PRE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8922b26a-300f-4e73-8748-f0b8984faa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] Loss=0.5019\n",
      "[2/10] Loss=0.1720\n",
      "[3/10] Loss=0.1695\n",
      "[4/10] Loss=0.1693\n",
      "[5/10] Loss=0.1693\n",
      "[6/10] Loss=0.1693\n",
      "[7/10] Loss=0.1692\n",
      "[8/10] Loss=0.1692\n",
      "[9/10] Loss=0.1692\n",
      "[10/10] Loss=0.1692\n",
      "✅ Exp2-Copy9x  Acc=0.5000  Macro-F1=0.5018\n",
      "📄 Metrics → result_exp2_copy_9x.json\n",
      "📄 Preds   → pred_exp2_copy_9x.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "run_exp2_copy_9x.py — 실험군 2\n",
    "  · Train : 70개 원본 × 9배 복제 = 630장 (증강 없음)\n",
    "  · Test  : split42_70-30.json 에 남은 30장\n",
    "  · Hyper : BATCH 16 · EPOCHS 10 · lr 1e-4 · wd 3e-4 · smoothing 0.05\n",
    "출력 : result_exp2_copy_9x.json / pred_exp2_copy_9x.csv\n",
    "\"\"\"\n",
    "\n",
    "# ── 0. 기본 import ────────────────────────────────────────────────\n",
    "import os, json, random, math, warnings, numpy as np, pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ── 1. 설정값 ────────────────────────────────────────────────────\n",
    "SEED   = 42\n",
    "CSV    = r\"C:\\Users\\ast\\Documents\\project\\train.csv\"\n",
    "IMG    = r\"C:\\Users\\ast\\Documents\\project\\train_images\"\n",
    "BATCH  = 16\n",
    "EPOCHS = 10\n",
    "LR     = 1e-4\n",
    "WD     = 3e-4\n",
    "SMOOTH = 0.05\n",
    "\n",
    "SPLIT  = \"split42_70-30.json\"\n",
    "OUT_MET= \"result_exp2_copy_9x.json\"\n",
    "OUT_PRE= \"pred_exp2_copy_9x.csv\"\n",
    "\n",
    "# ── 2. 시드 & 멀티프로세싱 고정 ───────────────────────────────────\n",
    "def seed_all(s):\n",
    "    random.seed(s); np.random.seed(s); os.environ[\"PYTHONHASHSEED\"]=str(s)\n",
    "    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
    "    torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "seed_all(SEED)\n",
    "import torch.multiprocessing as mp\n",
    "if mp.get_start_method(allow_none=True) != \"spawn\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "# ── 3. Dataset 정의 ──────────────────────────────────────────────\n",
    "class ScrapDataset(Dataset):\n",
    "    def __init__(self, df, tf, le):\n",
    "        self.df  = df.reset_index(drop=True).copy()\n",
    "        self.dir = IMG\n",
    "        self.tf  = tf\n",
    "        self.df[\"cls\"] = le.transform(self.df[\"weight_class\"])\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(os.path.join(self.dir, row.filename)).convert(\"RGB\")\n",
    "        return self.tf(img), torch.tensor(row.cls), row.filename\n",
    "\n",
    "plain_tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# ── 4. 70/30 split 고정 ──────────────────────────────────────────\n",
    "df = pd.read_csv(CSV)\n",
    "if os.path.exists(SPLIT):\n",
    "    idx = json.load(open(SPLIT)); train_idx, test_idx = idx[\"train\"], idx[\"test\"]\n",
    "else:\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        range(len(df)), train_size=70, test_size=30,\n",
    "        stratify=df[\"weight_class\"], random_state=SEED)\n",
    "    json.dump({\"train\":train_idx, \"test\":test_idx}, open(SPLIT,\"w\"))\n",
    "\n",
    "tr_df, te_df = df.iloc[train_idx], df.iloc[test_idx]\n",
    "le = LabelEncoder().fit(tr_df[\"weight_class\"])\n",
    "\n",
    "# ── 5. DataLoader (원본 9× 복제) ─────────────────────────────────\n",
    "base_train_ds = ScrapDataset(tr_df, plain_tf, le)       # 증강 X\n",
    "train_ds      = ConcatDataset([base_train_ds]*9)        # 70 × 9 = 630\n",
    "test_ds       = ScrapDataset(te_df, plain_tf, le)\n",
    "\n",
    "train_ld = DataLoader(train_ds, batch_size=BATCH, shuffle=True , num_workers=0)\n",
    "test_ld  = DataLoader(test_ds , batch_size=BATCH, shuffle=False, num_workers=0)\n",
    "\n",
    "# ── 6. 모델 & Optim & 스케줄러 ──────────────────────────────────\n",
    "class CoaTMedium(nn.Module):\n",
    "    def __init__(self, n_cls):\n",
    "        super().__init__()\n",
    "        self.net = timm.create_model('coat_lite_medium',\n",
    "                                     pretrained=True, num_classes=n_cls)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = CoaTMedium(len(le.classes_)).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "total_steps = len(train_ld) * EPOCHS\n",
    "warmup_steps = len(train_ld)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=lambda step: (step+1)/warmup_steps if step < warmup_steps\n",
    "             else 0.5*(1+math.cos(math.pi*(step-warmup_steps)/(total_steps-warmup_steps)))\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=SMOOTH)\n",
    "\n",
    "# ── 7. 학습 루프 ────────────────────────────────────────────────\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train(); epoch_loss = 0.0\n",
    "    for xb, yb, _ in train_ld:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(xb), yb)\n",
    "        loss.backward(); optimizer.step(); scheduler.step()\n",
    "        epoch_loss += loss.item() * xb.size(0)\n",
    "    print(f\"[{ep}/{EPOCHS}] Loss={epoch_loss/len(train_ld.dataset):.4f}\")\n",
    "\n",
    "# ── 8. 평가 ────────────────────────────────────────────────────\n",
    "model.eval(); yt, yp, rows = [], [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb, f in test_ld:\n",
    "        preds = model(xb.to(device)).argmax(1).cpu()\n",
    "        yt += yb.tolist(); yp += preds.tolist()\n",
    "        rows += list(zip(f, le.inverse_transform(preds.numpy())))\n",
    "acc = accuracy_score(yt, yp)\n",
    "f1  = f1_score(yt, yp, average=\"macro\")\n",
    "print(f\"✅ Exp2-Copy9x  Acc={acc:.4f}  Macro-F1={f1:.4f}\")\n",
    "\n",
    "# ── 9. 결과 저장 ───────────────────────────────────────────────\n",
    "json.dump({\"experiment\":\"exp2_copy_9x\",\"accuracy\":acc,\"macro_f1\":f1},\n",
    "          open(OUT_MET,\"w\"), indent=2)\n",
    "pd.DataFrame(rows, columns=[\"filename\",\"predicted_label\"])\\\n",
    "  .to_csv(OUT_PRE, index=False)\n",
    "print(f\"📄 Metrics → {OUT_MET}\\n📄 Preds   → {OUT_PRE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
