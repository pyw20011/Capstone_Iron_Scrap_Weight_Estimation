{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from timm import create_model\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "# 장치 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 데이터셋 (CIFAR10 예시, 원하는 데이터셋으로 교체 가능)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# 평가 함수\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# 학습 함수\n",
    "def train_one_epoch(model, optimizer, criterion, loader):\n",
    "    model.train()\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Optuna 목적 함수\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 샘플링\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-2)\n",
    "    drop_path_rate = trial.suggest_float('drop_path_rate', 0.0, 0.3)\n",
    "\n",
    "    # coat_medium 모델 생성\n",
    "    model = create_model(\n",
    "        'coat_medium',\n",
    "        pretrained=False,\n",
    "        num_classes=10,\n",
    "        drop_path_rate=drop_path_rate\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(5):  # 빠른 튜닝 목적\n",
    "        train_one_epoch(model, optimizer, criterion, train_loader)\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        trial.report(val_acc, epoch)\n",
    "\n",
    "        # Pruning 조건\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_acc\n",
    "\n",
    "# Optuna 실험 실행\n",
    "study = optuna.create_study(direction='maximize', pruner=MedianPruner(n_warmup_steps=2))\n",
    "study.optimize(objective, n_trials=30, timeout=3600)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
