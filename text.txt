### [CNN 기반 회귀 모델]

- **ResNet 계열 (Residual Networks)**
    - **ResNet-50, ResNet-101 등:**
        
        잔차 연결(residual connection)을 도입해 매우 깊은 네트워크에서도 안정적인 학습이 가능하며, ImageNet 등 대규모 데이터셋에서 사전 학습되어 강력한 특징 추출 능력을 가집니다.
        
- **VGG 계열 (Visual Geometry Group Networks)**
    - **VGG16, VGG19:**
        
        단순하고 일관된 구조로, 깊이가 증가함에도 불구하고 비교적 이해하기 쉽고, 특징 추출에 효과적입니다.
        
- **Inception 계열**
    - **InceptionV3, Inception-ResNet:**
        
        다양한 크기의 합성곱 필터를 병렬적으로 사용하여 여러 스케일의 특징을 동시에 추출할 수 있어, 복잡한 패턴 인식에 유리합니다.
        
- **MobileNet 계열**
    - **MobileNetV1, MobileNetV2, MobileNetV3:**
        
        경량화 모델로 모바일 및 임베디드 환경에서 효율적으로 동작하며, 전이 학습 시 적은 데이터셋으로도 좋은 성능을 발휘합니다.
        
- **EfficientNet 계열**
    - **EfficientNet-B0 ~ B7:**
        
        네트워크의 깊이, 너비, 해상도를 균형 있게 확장하는 방식으로 설계되어, 모델 크기와 연산량 대비 우수한 성능을 보입니다.
        
- **DenseNet 계열**
    - **DenseNet121, DenseNet169, DenseNet201:**
        
        각 계층이 이전 모든 계층과 연결되어 특징의 재사용성을 극대화하여, 효율적인 학습과 좋은 일반화 성능을 나타냅니다.
        

### [비전 트랜스포머 기반 회귀 모델]

- **Vision Transformer (ViT)**
    - Dosovitskiy et al.이 제안한 기본 ViT 모델로, ViT-B/16, ViT-L/16, ViT-H/14 등 다양한 크기의 모델이 있습니다.
    - 대규모 데이터셋(ImageNet 등)에서 학습되어 있으며, 전이 학습 시 기본 백본으로 많이 사용됩니다.
- **DeiT (Data-efficient Image Transformers)**
    - DeiT는 적은 양의 데이터로도 효과적으로 학습할 수 있도록 고안된 모델로, 전이 학습 환경에서 특히 유용합니다.
    - 모델 크기와 성능의 균형을 잘 맞춘 DeiT-S, DeiT-B 등 다양한 버전이 있습니다.
- **Swin Transformer**
    - 계층적 구조와 윈도우 기반 self-attention을 활용해 지역적 및 전역적 정보를 모두 효과적으로 캡처합니다.
    - Swin-T, Swin-S, Swin-B 등의 다양한 크기의 모델이 있으며, 다양한 컴퓨터 비전 태스크에서 전이 학습으로 좋은 성능을 보입니다.
- **BEiT (BERT Pre-training of Image Transformers)**
    - BEiT는 마스킹된 이미지 모델링(Masked Image Modeling)을 통해 사전 학습된 모델로, 전이 학습에 활용하기 적합합니다.
- **T2T-ViT (Tokens-to-Token Vision Transformer)**
    - 이미지 패치를 다시 토큰화하는 과정을 도입해, 더 세밀한 지역적 특징과 구조적 정보를 효과적으로 추출할 수 있도록 한 모델입니다.
