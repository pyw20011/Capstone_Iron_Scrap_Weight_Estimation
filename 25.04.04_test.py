import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import os

from config import cfg
from models.encoder import Encoder
from models.decoder import Decoder
from models.merger import Merger
from models.refiner import Refiner

cfg.IMG_SIZE = 224
cfg.MEAN = [0.5, 0.5, 0.5]
cfg.STD = [0.5, 0.5, 0.5]

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(image_path):
    image = Image.open(image_path).convert('RGB')
    transform = transforms.Compose([
        transforms.Resize((cfg.IMG_SIZE, cfg.IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=cfg.MEAN, std=cfg.STD)
    ])
    image = transform(image)
    return image.unsqueeze(0)  # [1, 3, H, W]

# DataParallel ì €ì¥ëœ state_dict ì²˜ë¦¬ í•¨ìˆ˜
def remove_module_prefix(state_dict):
    return {k.replace("module.", ""): v for k, v in state_dict.items()}

# ëª¨ë¸ ì´ˆê¸°í™”
encoder = Encoder(cfg).to(device)
decoder = Decoder(cfg).to(device)
merger = Merger(cfg).to(device)
refiner = Refiner(cfg).to(device)

# ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
checkpoint_path = './checkpoints/Pix2Vox-A-ShapeNet.pth'

# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
checkpoint = torch.load(checkpoint_path, map_location=device)

# "module." prefix ì œê±°í•˜ê³  ë¡œë“œ
encoder.load_state_dict(remove_module_prefix(checkpoint['encoder_state_dict']))
decoder.load_state_dict(remove_module_prefix(checkpoint['decoder_state_dict']))
merger.load_state_dict(remove_module_prefix(checkpoint['merger_state_dict']))
refiner.load_state_dict(remove_module_prefix(checkpoint['refiner_state_dict']))

# í‰ê°€ ëª¨ë“œ ì„¤ì •
encoder.eval()
decoder.eval()
merger.eval()
refiner.eval()

# ====== ì´ë¯¸ì§€ ê²½ë¡œ ì…ë ¥ ======
image_path = './chair.jpg'  # ì´ ë¶€ë¶„ì„ ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì •

# ====== ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì˜ˆì¸¡ ======
images = preprocess_image(image_path).to(device)  # [1, 3, 224, 224]
images = images.unsqueeze(1)  # [1, 1, 3, 224, 224] (encoder ìš”êµ¬ì‚¬í•­ ë§ì¶¤)

image_features = encoder(images)  # [1, n, 512, 28, 28]
raw_features, gen_volumes = decoder(image_features)  # ğŸ”¹ ìˆ˜ì •ëœ ë¶€ë¶„

# ğŸ”¹ í¬ê¸° ì¶œë ¥ (ë””ë²„ê¹… ìš©ë„)
print("Raw Feature Shape:", raw_features.shape)  # [1, n_views, 9, 32, 32, 32]
print("Generated Volume Shape:", gen_volumes.shape)  # [1, n_views, 32, 32, 32]

# ğŸ”¹ `gen_volumes`ë§Œ ì‚¬ìš©í•´ì„œ `coarse_volumes` ìƒì„±
coarse_volumes = gen_volumes  # [B, n_views, 32, 32, 32]

# ğŸ”¹ Merger ì ìš© (raw_features ì¶”ê°€)
merged_volume = merger(raw_features, coarse_volumes)  # [1, 32, 32, 32]

# ğŸ”¹ Refinement ì ìš©
refined_volume = refiner(merged_volume)

# ğŸ”¹ ì´ì§„í™” ë° ì¶œë ¥
binary_voxel = (refined_volume > 0.3).float()

# ê²°ê³¼ í™•ì¸ (ê°„ë‹¨íˆ í˜•íƒœ ì¶œë ¥)
print("Predicted Voxel Shape:", binary_voxel.shape)  # [1, 32, 32, 32]
print("Non-zero voxel count:", binary_voxel.sum().item())




# --------------------------- ì‹œê°í™” ------------------------------------------

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# NumPy ë³€í™˜
voxel_data = binary_voxel.squeeze().cpu().numpy()  # [32, 32, 32]

# 3D ì‹œê°í™”
fig = plt.figure(figsize=(6, 6))
ax = fig.add_subplot(111, projection='3d')

# í™œì„±í™”ëœ Voxel ì¢Œí‘œ ì¶”ì¶œ
x, y, z = voxel_data.nonzero()

ax.scatter(x, y, z, zdir='z', c='black')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')

plt.show()
